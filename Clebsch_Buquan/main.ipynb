{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型A\n",
    "class ModelA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelA, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型B\n",
    "class ModelB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelB, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 64, kernel_size=3, padding=1),  # 7 channels: 3 for velocity, 4 for abcd\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, abcd):\n",
    "        x = torch.cat([x, abcd], dim=1)  # Concatenate velocity and abcd inputs\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  示例训练循环（适用于模型A和模型B）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型A的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型B的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型B的训练函数需要接受三项输入\n",
    "def train_model_b(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for masked_velocity, abcd, targets in dataloader:\n",
    "        masked_velocity, abcd, targets = masked_velocity.to(device), abcd.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(masked_velocity, abcd)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * masked_velocity.size(0)\n",
    "    return running_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  实例化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = ModelA().to(device)\n",
    "model_b = ModelB().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer_a = optim.Adam(model_a.parameters(), lr=0.001)\n",
    "optimizer_b = optim.Adam(model_b.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义数据类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VelocityDataset(Dataset):\n",
    "    def __init__(self, velocity_files, abcd_files=None, mask_ratio=0.2):\n",
    "        \"\"\"\n",
    "        velocity_files: list of paths to velocity npy files\n",
    "        abcd_files: list of paths to abcd npy files (only for Model B)\n",
    "        mask_ratio: percentage of the velocity field to mask (e.g., 0.2 means 20% of the field will be masked)\n",
    "        \"\"\"\n",
    "        self.velocity_files = velocity_files\n",
    "        self.abcd_files = abcd_files\n",
    "        self.mask_ratio = mask_ratio\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.velocity_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 加载速度场\n",
    "        velocity = np.load(self.velocity_files[idx])\n",
    "\n",
    "        # 生成掩码\n",
    "        mask = np.random.rand(*velocity.shape) < self.mask_ratio\n",
    "        masked_velocity = velocity.copy()\n",
    "        masked_velocity[mask] = 0  # 掩盖部分速度场数据\n",
    "\n",
    "        # 转换为PyTorch张量\n",
    "        masked_velocity = torch.from_numpy(masked_velocity).float()\n",
    "        velocity = torch.from_numpy(velocity).float()\n",
    "\n",
    "        if self.abcd_files is not None:\n",
    "            # 加载并转换物理量 a, b, c, d\n",
    "            abcd = np.load(self.abcd_files[idx])\n",
    "            abcd = torch.from_numpy(abcd).float()\n",
    "            return masked_velocity, abcd, velocity  # 返回模型B的输入和目标\n",
    "        else:\n",
    "            return masked_velocity, velocity  # 返回模型A的输入和目标\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取训练和测试集的文件列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_velocity_files = [os.path.join('data/processed/train/velocities', f) for f in os.listdir('data/processed/train/velocities')]\n",
    "train_abcd_files = [os.path.join('data/processed/train/abcd', f) for f in os.listdir('data/processed/train/abcd')]\n",
    "\n",
    "test_velocity_files = [os.path.join('data/processed/test/velocities', f) for f in os.listdir('data/processed/test/velocities')]\n",
    "test_abcd_files = [os.path.join('data/processed/test/abcd', f) for f in os.listdir('data/processed/test/abcd')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建Dataset实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import NpyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_a = NpyDataset(velocity_dir='data/processed/train/velocities', mask_ratio=0.2)\n",
    "train_dataset_b = NpyDataset(velocity_dir='data/processed/train/velocities', abcd_dir='data/processed/train/abcd', mask_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_a = NpyDataset(velocity_dir='data/processed/test/velocities', mask_ratio=0.2)\n",
    "test_dataset_b = NpyDataset(velocity_dir='data/processed/test/velocities', abcd_dir='data/processed/test/abcd', mask_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建DataLoader实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_a = DataLoader(train_dataset_a, batch_size=4, shuffle=True, num_workers=0)\n",
    "train_loader_b = DataLoader(train_dataset_b, batch_size=4, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_a = DataLoader(test_dataset_a, batch_size=4, shuffle=False, num_workers=0)\n",
    "test_loader_b = DataLoader(test_dataset_b, batch_size=4, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device, is_model_b=False):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            if is_model_b:\n",
    "                masked_velocity, abcd, targets = data\n",
    "                masked_velocity, abcd, targets = masked_velocity.to(device), abcd.to(device), targets.to(device)\n",
    "                outputs = model(masked_velocity, abcd)\n",
    "            else:\n",
    "                inputs, targets = data\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * targets.size(0)\n",
    "    \n",
    "    avg_loss = running_loss / len(dataloader.dataset)\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Model A Train Loss: 0.0003, Validation Loss: 0.0002\n",
      "Epoch 2/10, Model A Train Loss: 0.0002, Validation Loss: 0.0002\n",
      "Epoch 3/10, Model A Train Loss: 0.0002, Validation Loss: 0.0001\n",
      "Epoch 4/10, Model A Train Loss: 0.0002, Validation Loss: 0.0001\n",
      "Epoch 5/10, Model A Train Loss: 0.0002, Validation Loss: 0.0001\n",
      "Epoch 6/10, Model A Train Loss: 0.0001, Validation Loss: 0.0001\n",
      "Epoch 7/10, Model A Train Loss: 0.0001, Validation Loss: 0.0001\n",
      "Epoch 8/10, Model A Train Loss: 0.0001, Validation Loss: 0.0001\n",
      "Epoch 9/10, Model A Train Loss: 0.0001, Validation Loss: 0.0001\n",
      "Epoch 10/10, Model A Train Loss: 0.0001, Validation Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_a = train(model_a, train_loader_a, optimizer_a, criterion, device)\n",
    "    val_loss_a = validate(model_a, test_loader_a, criterion, device, is_model_b=False)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Model A Train Loss: {train_loss_a:.4f}, Validation Loss: {val_loss_a:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Model B Train Loss: 0.0004, Validation Loss: 0.0003\n",
      "Epoch 2/10, Model B Train Loss: 0.0002, Validation Loss: 0.0002\n",
      "Epoch 3/10, Model B Train Loss: 0.0002, Validation Loss: 0.0002\n",
      "Epoch 4/10, Model B Train Loss: 0.0002, Validation Loss: 0.0002\n",
      "Epoch 5/10, Model B Train Loss: 0.0002, Validation Loss: 0.0001\n",
      "Epoch 6/10, Model B Train Loss: 0.0002, Validation Loss: 0.0001\n",
      "Epoch 7/10, Model B Train Loss: 0.0002, Validation Loss: 0.0001\n",
      "Epoch 8/10, Model B Train Loss: 0.0002, Validation Loss: 0.0001\n",
      "Epoch 9/10, Model B Train Loss: 0.0002, Validation Loss: 0.0001\n",
      "Epoch 10/10, Model B Train Loss: 0.0001, Validation Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss_b = train_model_b(model_b, train_loader_b, optimizer_b, criterion, device)\n",
    "    val_loss_b = validate(model_b, test_loader_b, criterion, device, is_model_b=True)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Model B Train Loss: {train_loss_b:.4f}, Validation Loss: {val_loss_b:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
