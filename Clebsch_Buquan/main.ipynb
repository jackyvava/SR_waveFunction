{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型A\n",
    "class ModelA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelA, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型B\n",
    "class ModelB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelB, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 64, kernel_size=3, padding=1),  # 7 channels: 3 for velocity, 4 for abcd\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, abcd):\n",
    "        x = torch.cat([x, abcd], dim=1)  # Concatenate velocity and abcd inputs\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  示例训练循环（适用于模型A和模型B）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  实例化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = ModelA().to(device)\n",
    "model_b = ModelB().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer_a = optim.Adam(model_a.parameters(), lr=0.001)\n",
    "optimizer_b = optim.Adam(model_b.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义数据类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VelocityDataset(Dataset):\n",
    "    def __init__(self, velocity_files, abcd_files=None, mask_ratio=0.2):\n",
    "        \"\"\"\n",
    "        velocity_files: list of paths to velocity npy files\n",
    "        abcd_files: list of paths to abcd npy files (only for Model B)\n",
    "        mask_ratio: percentage of the velocity field to mask (e.g., 0.2 means 20% of the field will be masked)\n",
    "        \"\"\"\n",
    "        self.velocity_files = velocity_files\n",
    "        self.abcd_files = abcd_files\n",
    "        self.mask_ratio = mask_ratio\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.velocity_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 加载速度场\n",
    "        velocity = np.load(self.velocity_files[idx])\n",
    "\n",
    "        # 生成掩码\n",
    "        mask = np.random.rand(*velocity.shape) < self.mask_ratio\n",
    "        masked_velocity = velocity.copy()\n",
    "        masked_velocity[mask] = 0  # 掩盖部分速度场数据\n",
    "\n",
    "        # 转换为PyTorch张量\n",
    "        masked_velocity = torch.from_numpy(masked_velocity).float()\n",
    "        velocity = torch.from_numpy(velocity).float()\n",
    "\n",
    "        if self.abcd_files is not None:\n",
    "            # 加载并转换物理量 a, b, c, d\n",
    "            abcd = np.load(self.abcd_files[idx])\n",
    "            abcd = torch.from_numpy(abcd).float()\n",
    "            return masked_velocity, abcd, velocity  # 返回模型B的输入和目标\n",
    "        else:\n",
    "            return masked_velocity, velocity  # 返回模型A的输入和目标\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取训练和测试集的文件列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_velocity_files = [os.path.join('data/processed/train/velocities', f) for f in os.listdir('data/processed/train/velocities')]\n",
    "train_abcd_files = [os.path.join('data/processed/train/abcd', f) for f in os.listdir('data/processed/train/abcd')]\n",
    "\n",
    "test_velocity_files = [os.path.join('data/processed/test/velocities', f) for f in os.listdir('data/processed/test/velocities')]\n",
    "test_abcd_files = [os.path.join('data/processed/test/abcd', f) for f in os.listdir('data/processed/test/abcd')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建Dataset实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset_a = VelocityDataset(train_velocity_files, mask_ratio=0.2)\n",
    "train_dataset_b = VelocityDataset(train_velocity_files, train_abcd_files, mask_ratio=0.2)\n",
    "\n",
    "test_dataset_a = VelocityDataset(test_velocity_files, mask_ratio=0.2)\n",
    "test_dataset_b = VelocityDataset(test_velocity_files, test_abcd_files, mask_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建DataLoader实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader_a = DataLoader(train_dataset_a, batch_size=2, shuffle=True, num_workers=0)\n",
    "train_loader_b = DataLoader(train_dataset_b, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "test_loader_a = DataLoader(test_dataset_a, batch_size=4, shuffle=False, num_workers=0)\n",
    "test_loader_b = DataLoader(test_dataset_b, batch_size=4, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# 设置训练的轮数\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 4\u001b[0m     train_loss_a \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Model A Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss_a\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 11\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 5  # 设置训练的轮数\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_a = train(model_a, train_loader_a, optimizer_a, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Model A Loss: {train_loss_a:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
